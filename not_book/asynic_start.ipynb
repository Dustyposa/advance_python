{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import (\n",
    "    List,\n",
    ")\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模拟爬虫的操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 同步测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_page(url: str) -> None:\n",
    "    \"\"\"完成抓取\"\"\"\n",
    "    print(f\"crawling {url}\")\n",
    "    sleep_time = int(url.rsplit(\"_\", maxsplit=1)[-1])\n",
    "    time.sleep(sleep_time)\n",
    "    print(f\"抓取{url}完成\")\n",
    "\n",
    "def main(urls: List[str]) -> None:\n",
    "    \"\"\"批量抓取\"\"\"\n",
    "    for url in urls:\n",
    "        crawl_page(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawling url_1\n",
      "抓取url_1完成\n",
      "crawling url_2\n",
      "抓取url_2完成\n",
      "crawling url_3\n",
      "抓取url_3完成\n",
      "crawling url_4\n",
      "抓取url_4完成\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%time main(['url_1', \"url_2\", \"url_3\", \"url_4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**一共10s，这是同步的正常情况。我们看看异步的情况。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def crawl_page(url: str) -> None:\n",
    "    \"\"\"声明异步类型的抓取函数\"\"\"\n",
    "    print(f\"crawling {url}\")\n",
    "    sleep_time = int(url.rsplit(\"_\", maxsplit=1)[-1])\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    print(f\"抓取{url}完成\")\n",
    "\n",
    "async def asy_main(urls: List[str]) -> None:\n",
    "    \"\"\"声明异步批量抓取\"\"\"\n",
    "    for url in urls:\n",
    "        await crawl_page(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawling url_1\n",
      "抓取url_1完成\n",
      "crawling url_2\n",
      "抓取url_2完成\n",
      "crawling url_3\n",
      "抓取url_3完成\n",
      "crawling url_4\n",
      "抓取url_4完成\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%time asyncio.run(asy_main(['url_1', \"url_2\", \"url_3\", \"url_4\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是实际花费时间还是10s，那么很明显，这里并没有异步执行。为什么呢？  \n",
    "那么肯定是循环 `await的问题` 。  \n",
    "`await` 会阻塞等待执行的完成，但是在 `async` 装饰后的函数中（此时变成了一个携程对象），你又不得不使用`await`，那么我们怎么让他异步执行呢？  \n",
    "我们用 `create_task` 来实现。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def crawl_page(url: str) -> None:\n",
    "    \"\"\"声明异步类型的抓取函数\"\"\"\n",
    "    print(f\"crawling {url}\")\n",
    "    sleep_time = int(url.rsplit(\"_\", maxsplit=1)[-1])  # type: int\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    print(f\"抓取{url}完成\")\n",
    "\n",
    "async def asy_main(urls: List[str]) -> None:\n",
    "    \"\"\"声明异步批量抓取\"\"\"\n",
    "    tasks = [asyncio.create_task(crawl_page(url)) for url in urls]\n",
    "    for task in tasks:\n",
    "        await task  # 等待完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawling url_1\n",
      "crawling url_2\n",
      "crawling url_3\n",
      "crawling url_4\n",
      "抓取url_1完成\n",
      "抓取url_2完成\n",
      "抓取url_3完成\n",
      "抓取url_4完成\n",
      "Wall time: 4 s\n"
     ]
    }
   ],
   "source": [
    "%time asyncio.run(asy_main(['url_1', \"url_2\", \"url_3\", \"url_4\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**学过线程或者进程的同学应该觉得很熟悉，因为进程或者线程需要初始化一个任务对象，然后再运行。所以其实这里都是相通的， 不过异步创建就会运行，就不用手动运行了。**  \n",
    "经过改造之后，我们发现运行速度变快了。只用了最长的运行时间，即 4s.  \n",
    "是不是很方便就做出来了！没错，python的异步就是为了成为新的宠儿，才变得这么简单强大！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**当然, for 循环运行任务看起来不太优雅，我们有另一种写法。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def new_asy_main(urls: List[str]) -> None:\n",
    "    \"\"\"声明异步批量抓取\"\"\"\n",
    "    tasks = (asyncio.create_task(crawl_page(url)) for url in urls)\n",
    "    asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1e+03 µs\n",
      "crawling url_1\n",
      "crawling url_2\n",
      "crawling url_3\n",
      "crawling url_4\n",
      "抓取url_1完成\n",
      "抓取url_2完成\n",
      "抓取url_3完成\n",
      "抓取url_4完成\n"
     ]
    }
   ],
   "source": [
    "%time asyncio.run(new_asy_main(['url_1', \"url_2\", \"url_3\", \"url_4\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们把 `tasks` 优化成为了一个生成器，然后调用 `asyncio.gather` 解包 `tasks` ，这样写起来更加清晰易懂。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "异步详解\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before await\n",
      "worker_1 start\n",
      "worker_2 start\n",
      "worker_1 done\n",
      "awaited worker_1\n",
      "worker_2 done\n",
      "awaited worker_2\n",
      "Wall time: 1.99 s\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def worker_1():\n",
    "    print('worker_1 start')\n",
    "    await asyncio.sleep(1)\n",
    "    print('worker_1 done')\n",
    "\n",
    "async def worker_2():\n",
    "    print('worker_2 start')\n",
    "    await asyncio.sleep(2)\n",
    "    print('worker_2 done')\n",
    "\n",
    "async def main():\n",
    "    task1 = asyncio.create_task(worker_1())  # 创建携程任务 并执行\n",
    "    task2 = asyncio.create_task(worker_2())  # 创建携程任务 并执行\n",
    "    print('before await')\n",
    "    await task1  # 等待task1 完成\n",
    "    print('awaited worker_1')\n",
    "    await task2  # 等待task2 完成\n",
    "    print('awaited worker_2')\n",
    "\n",
    "%time asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "producer_1 put a val: 3\n",
      "producer_2 put a val: 2\n",
      "consumer_1 get a val: 3\n",
      "consumer_2 get a val: 2\n",
      "producer_1 put a val: 10\n",
      "producer_2 put a val: 3\n",
      "consumer_2 get a val: 10\n",
      "consumer_1 get a val: 3\n",
      "producer_1 put a val: 1\n",
      "producer_2 put a val: 6\n",
      "consumer_1 get a val: 1\n",
      "consumer_2 get a val: 6\n",
      "producer_1 put a val: 1\n",
      "producer_2 put a val: 7\n",
      "consumer_1 get a val: 1\n",
      "consumer_2 get a val: 7\n",
      "producer_1 put a val: 8\n",
      "producer_2 put a val: 8\n",
      "consumer_1 get a val: 8\n",
      "consumer_2 get a val: 8\n",
      "[CancelledError(), CancelledError(), None, None]\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import random\n",
    "\n",
    "async def consumer(queue, id):\n",
    "    while True:\n",
    "        val = await queue.get()\n",
    "        print('{} get a val: {}'.format(id, val))\n",
    "        await asyncio.sleep(1)\n",
    "\n",
    "async def producer(queue, id):\n",
    "    for i in range(5):\n",
    "        val = random.randint(1, 10)\n",
    "        await queue.put(val)\n",
    "        print('{} put a val: {}'.format(id, val))\n",
    "        await asyncio.sleep(1)\n",
    "\n",
    "async def main():\n",
    "    queue = asyncio.Queue()\n",
    "\n",
    "    consumer_1 = asyncio.create_task(consumer(queue, 'consumer_1'))\n",
    "    consumer_2 = asyncio.create_task(consumer(queue, 'consumer_2'))\n",
    "\n",
    "    producer_1 = asyncio.create_task(producer(queue, 'producer_1'))\n",
    "    producer_2 = asyncio.create_task(producer(queue, 'producer_2'))\n",
    "\n",
    "    await asyncio.sleep(10)\n",
    "    consumer_1.cancel()\n",
    "    consumer_2.cancel()\n",
    "    \n",
    "    res = await asyncio.gather(consumer_1, consumer_2, producer_1, producer_2, return_exceptions=True)\n",
    "    print(res)\n",
    "\n",
    "%time asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pint\n",
    "  - ####  add_done_callback 回调。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
